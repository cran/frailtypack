% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/jointSurroPenal.R
\name{jointSurroPenal}
\alias{jointSurroPenal}
\title{Fit the one-step Joint surrogate model for the evaluation of a canditate surrogate endpoint}
\usage{
jointSurroPenal(data, maxit=40, indicator.zeta = 1, 
   indicator.alpha = 1, frail.base = 1, n.knots = 6, 
   LIMparam = 0.001, LIMlogl = 0.001, LIMderiv = 0.001, 
   nb.mc = 300, nb.gh = 32, nb.gh2 = 20, adaptatif = 0, 
   int.method = 2, nb.iterPGH = 5, nb.MC.kendall = 10000, 
   nboot.kendall = 1000, true.init.val = 0, 
   theta.init = 1, sigma.ss.init = 0.5, sigma.tt.init = 0.5, 
   sigma.st.init = 0.48, gamma.init = 0.5, alpha.init = 1, 
   zeta.init = 1, betas.init = 0.5, betat.init = 0.5, scale = 1, 
   random.generator = 1, kappa.use = 4, random = 0, 
   random.nb.sim = 0, seed = 0, init.kappa = NULL, nb.decimal = 4, 
   print.times = TRUE, print.iter=FALSE)
}
\arguments{
\item{data}{A \code{\link{data.frame}} containing at least \code{7} variables intitled: 
\itemize{
\item{\code{patienID:} A numeric, that represents the patient's identifier, must be unique;}
\item{\code{trialID:} A numeric, that represents the trial in which each patient was randomized;}
\item{\code{timeS:} The follow up time associated with the surrogate endpoint;}
\item{\code{statusS:} The event indicator associated with the surrogate endpoint. Normally 
0 = no event, 1 = event;}
\item{\code{timeT:} The follow up time associated with the true endpoint;}
\item{\code{statusT:} The event indicator associated with the true endpoint. Normally 
0 = no event, 1 = event;}
\item{\code{trt:} The treatment indicator for each patient, with 1 = treated, 0 = untreated.}
}}

\item{maxit}{maximum number of iterations for the Marquardt algorithm.
Default is \code{40}.}

\item{indicator.zeta}{A binary, indicates whether the power's parameter \eqn{\zeta} should 
be estimated (1) or not (0). If \code{0}, \eqn{\zeta} will be set to \code{1} during estimation. 
The default is \code{1}. This parameter can be seted to \code{0} in case of convergence and 
identification issues.}

\item{indicator.alpha}{A binary, indicates whether the power's parameter \eqn{\alpha} should 
be estimated (1) or not (0). If \code{0}, \eqn{\alpha} will be set to \code{1} during estimation.
The default is 1.}

\item{frail.base}{Considered the heterogeneity between trial on the baseline risk (\code{1}), using 
the shared cluster specific frailties (\eqn{u_i}), or not (\code{0}). The default is \code{1}.}

\item{n.knots}{integer giving the number of knots to use. Value required in
the penalized likelihood estimation.  It corresponds to the (n.knots+2)
splines functions for the approximation of the hazard or the survival
functions.  We estimate I or M-splines of order 4. When the user set a
number of knots equals to k (n.knots=k) then the number of interior knots
is (k-2) and the number of splines is (k-2)+order.  Number of knots must be
between 4 and 20. (See \code{\link{frailtyPenal}} for more details).}

\item{LIMparam}{Convergence threshold of the Marquardt algorithm for the
parameters, \eqn{10^{-3}} by default (See \code{\link{frailtyPenal}} for more details).}

\item{LIMlogl}{Convergence threshold of the Marquardt algorithm for the
log-likelihood, \eqn{10^{-3}} by default (See \code{\link{frailtyPenal}} for more details).}

\item{LIMderiv}{Convergence threshold of the Marquardt algorithm for the gradient, \eqn{10^{-3}} by default 
(See \code{\link{frailtyPenal}} for more details).}

\item{nb.mc}{Number of samples considered in the Monte-Carlo integration. Required in case 
\code{int.method} is equals to \code{0}, \code{2} or \code{4}. A value between 100 and 300 most often gives 
good results. However, beyond 300, the program takes a lot of time to estimate the parameters.
The default is \code{300}.}

\item{nb.gh}{Number of nodes for the Gaussian-Hermite quadrature. It can
be chosen among 5, 7, 9, 12, 15, 20 and 32. The default is 32.}

\item{nb.gh2}{Number of nodes for the Gauss-Hermite quadrature used to re-estimate the model, 
in case of non-convergence, defined as previously. The default is \code{20}.}

\item{adaptatif}{A binary, indicates whether the pseudo adaptive Gaussian-Hermite quadrature \code{(1)} or the classical
Gaussian-Hermite quadrature \code{(0)} is used. The default is \code{0}.}

\item{int.method}{A numeric, indicates the integration method: \code{0} for Monte carlo, 
\code{1} for Gaussian-Hermite quadrature, \code{2} for a combination of both Gaussian-Hermite quadrature to 
integrate over the individual-level random effects and Monte carlo to integrate over the trial-level
random effects, \code{4} for a combination of both Monte carlo to integrate over 
the individual-level random effects and Gaussian-Hermite quadrature to integrate over the trial-level
random effects. The default is \code{2}.}

\item{nb.iterPGH}{Number of iterations before the re-estimation of the posterior random effects,
in case of the two-steps pseudo-adaptive Gaussian-hermite quadrature. If set to \code{0} there is no 
re-estimation". The default is \code{5}.}

\item{nb.MC.kendall}{Number of generated points used with the Monte-Carlo to estimate
integrals in the Kendall's \eqn{\tau} formulation. Beter to use at least 4000 points for
stable reseults. The default is \code{10000}.}

\item{nboot.kendall}{Number of samples considered in the parametric bootstrap to estimate the confidence
interval of the Kendall's \eqn{\tau}. The default is \code{1000}.}

\item{true.init.val}{Numerical value. Indicates if the given initial values to parameters \code{(0)} should be considered. 
If set to \code{2}, \eqn{\alpha} and \eqn{\gamma} are initialised using two separed shared frailty model 
(see \code{\link{frailtyPenal}} for more details); \eqn{\sigma^2_{v_S}}, \eqn{\sigma^2_{v_T}} and
\eqn{\sigma_{v_{ST}}} are fixed by the user or the default values; \eqn{\zeta}, 
\eqn{\theta}, \eqn{\beta_S} and \eqn{\beta_T} are initialized using a classical joint 
frailty model, considering individual level random effects. If the joint frailty model is 
faced to convergence issues, \eqn{\beta_S} and \eqn{\beta_T} are initialized using 
two shared frailty models.  In all others scenarios, if the simplified model does not converge,
default given parameters values are used. Initial values for spline's associated parameters 
are fixed to \code{0.5}. The default for this argument is \code{0}.}

\item{theta.init}{Initial values for \eqn{\theta}, required if \code{true.init.val} 
is set to \code{0} or \code{2}. The default is \code{1}.}

\item{sigma.ss.init}{Initial values for \eqn{\sigma^2_{v_S}}, required if \code{true.init.val} 
is set to \code{0} or \code{2}. The default is \code{0.5}.}

\item{sigma.tt.init}{Initial values for \eqn{\sigma^2_{v_T}}, required if \code{true.init.val} 
is set to \code{0} or \code{2}. The default is \code{0.5}.}

\item{sigma.st.init}{Initial values for \eqn{\sigma_{v_{ST}}}, required if \code{true.init.val} 
is set to \code{0} or \code{2}. The default is \code{0.48}.}

\item{gamma.init}{Initial values for \eqn{\gamma}, required if \code{true.init.val} 
is set to \code{0} or \code{2}. The default is \code{0.5}.}

\item{alpha.init}{Initial values for \eqn{\alpha}, required if \code{true.init.val} 
is set to \code{0} or \code{2}. The default is \code{1}.}

\item{zeta.init}{Initial values for \eqn{\zeta}, required if \code{true.init.val} 
is set to \code{0} or \code{2}. The default is \code{1}.}

\item{betas.init}{Initial values for \eqn{\beta_S}, required if \code{true.init.val} 
is set to \code{0} or \code{2}. The default is \code{0.5}.}

\item{betat.init}{Initial values for \eqn{\beta_T}, required if \code{true.init.val} 
is set to \code{0} or \code{2}. The default is \code{0.5}.}

\item{scale}{A numeric that allows to rescale the survival times, to avoid numerical 
problems in case of some convergence issues. If no change is need the argument is set to 1, the default value. 
eg: 365 aims to convert days to years ".}

\item{random.generator}{Random number generator to use by the Fortran compiler, 
\code{1} for the intrinsec subroutine \code{Random_number} and \code{2} for the 
subroutine \code{uniran()}. The default is \code{1}. In case of convergence problem 
with \code{int.method} set to \code{0}, \code{2} or \code{4}, that requires  
integration by Monte-Carlo, user could change the random numbers generator.}

\item{kappa.use}{A numeric, that indicates how to manage the smoothing parameters \code{k_1} 
and \code{k_2} in case of convergence issues. If it is set to \code{1}, 
the given smoothing parameters or those obtained by cross-validation are used. 
If it is set to \code{3}, the associated smoothing parameters are successively divided by 10, 
in case of convergence issues until 5 times. If it is set to \code{4}, the management of the
smoothing parameter is as in case \code{1}, follows by the successive division as described 
in case \code{3} and preceded by the changing of the number of nodes for the Gauss-Hermite quadrature. 
The default is \code{4}.}

\item{random}{A binary that says if we reset the random number generation with a different environment 
at each call \code{(1)} or not \code{(0)}. If it is set to \code{1}, we use the computer clock 
as seed. In the last case, it is not possible to reproduce the generated datasets". 
The default is \code{0}. Required if \code{random.generator} is set to 1.}

\item{random.nb.sim}{If \code{random} is set to \code{1}, a binary that indicates the number 
of generations that will be made.}

\item{seed}{The seed to use for data (or samples) generation. required if \code{random} is set to \code{0}. 
The default is \code{0}.}

\item{init.kappa}{smoothing parameter used to penalized the log-likelihood. By default (init.kappa = NULL) the values used 
are obtain by cross-validation.}

\item{nb.decimal}{Number of decimal required for results presentation.}

\item{print.times}{a logical parameter to print estimation time. Default
is TRUE.}

\item{print.iter}{a logical parameter to print iteration process. Default
is FALSE.}
}
\value{
This function return an object of class jointSurroPenal with elements :

   \item{EPS}{A vector containing the obtained convergence thresholds with the Marquardt algorithm,  
    for the parameters, the log-likelihood and for the gradient;}
   \item{b}{A vector containing estimates for the splines parameter's, 
   the power's parameter \eqn{\zeta} (if \code{indicator.zeta} is set to \code{1}),
    the standard error of the shared individual-level frailty \eqn{\omega_{ij}} (\eqn{\theta}), elements of the
    lower triangular matrix (L) from the Cholesky decomposition such that \eqn{\Sigma = LL^T}, with \eqn{\Sigma} 
    the covariances of the random effects \eqn{(v_{S_i},v_{T_i})}, the coefficient \eqn{\alpha} 
    (if \code{indicator.alpha} is set to \code{1}), the satandard error of the random effect \eqn{u_i} and the 
    regression coefficients \eqn{\beta_S} and \eqn{\beta_T};}
    \item{varH}{The variance matrix of all parameters in \code{b} (before positivity constraint transformation 
   for the variance of the measurement error, for which the delta method is used);}
   \item{varHIH}{The robust estimation of the variance matrix of all parameters in \code{b};}
   \item{loglikPenal}{The complete marginal penalized log-likelihood;}
   \item{LCV}{the approximated likelihood cross-validation criterion in the semiparametric case (with \code{H}
    minus the converged Hessian matrix, and \code{l(.)} the full log-likelihood).
   \deqn{LCV = \frac{1}{n}(trace(H^{-1}_{pl}H) - l(.));}}
   \item{xS}{vector of times for surrogate endpoint where both survival and hazard function are estimated. 
   By default seq(0,max(time),length=99), where time is the vector of survival times;}
   \item{lamS}{array (dim = 3) of hazard estimates and confidence bands, for surrogate endpoint;}
   \item{survS}{array (dim = 3) of baseline survival estimates and confidence bands, for surrogate endpoint;}
   \item{xT}{vector of times for true endpoint where both survival and hazard function are estimated. 
   By default seq(0, max(time), length = 99), where time is the vector of survival times;}
   \item{lamT}{array (dim = 3) of hazard estimates and confidence bands, for true endpoint;}
   \item{survT}{array (dim = 3) of baseline survival estimates and confidence bands, for true endpoint;}
   \item{n.iter}{number of iterations needed to converge;}
   \item{theta}{Estimate for \eqn{\theta};}
   \item{gamma}{Estimate for \eqn{\gamma};}
   \item{alpha}{Estimate for \eqn{\alpha};}
   \item{zeta}{Estimate for \eqn{\zeta};}
   \item{sigma.s}{Estimate for \eqn{\sigma_S};}
   \item{sigma.t}{Estimate for \eqn{\sigma_T};}
   \item{sigma.st}{Estimate for \eqn{\sigma_{ST}};}
   \item{beta.s}{Estimate for \eqn{\beta_S};}
   \item{beta.t}{Estimate for \eqn{\beta_T};}
   \item{ui}{A binary, that indicates if the heterogeneity between trial on the baseline risk 
   has been Considered (\code{1}), using the shared cluster specific frailties (\eqn{u_i}), 
   or not (\code{0});}
   \item{ktau}{The Kendall's \eqn{\tau} with the correspondant 95  \eqn{\%} CI computed using the parametric bootstrap;}
   \item{R2.boot}{The \eqn{R^2_{trial}} with the correspondant 95 \eqn{\%} CI computed using the parametric bootstrap;}
   \item{Coefficients}{The estimates with the corresponding standard errors and the 95 \eqn{\%} CI}
   \item{kappa}{Positive smoothing parameters used for convergence. These values could be different to initial 
   values if \code{kappa.use} is set to \code{3} or \code{4};}
   \item{scale}{The value used to rescale the survival times}
   \item{data}{The dataset used in the model}
   \item{varcov.Sigma}{covariance matrix of (\eqn{\hat{\sigma_S}},\eqn{\hat{\sigma_{T}}}, \eqn{\hat{\sigma_{ST}}})
   obtained from the delta-method}
   \item{parameter}{list of all arguments used in the model}
}
\description{
{
\if{html}{\bold{Joint Frailty Surrogate model definition} 

Fit the one-step Joint surrogate model for the evaluation of a canditate surrogate endpoint, 
with different integration methods on the random effects, using a semiparametric penalized 
likelihood estimation. This approach extends that of Burzykowski \code{et al.} (2001) by 
including in the same joint frailty model the individual-level and the trial-level random effects.
 
For the j\out{<sup>th</sup>} subject (j=1,...,n\out{<sub>i</sub>}) of the i\out{<sup>th</sup>} 
trial i (i=1,...,G), the joint surrogate model is defined as follows:

{\figure{surromodel1.png}{options: width="100\%"}}

where,
\eqn{\omega}\out{<sub>ij</sub>} \out{&#126;} \eqn{N}(0,\eqn{\theta}), u\out{<sub>i</sub>} \out{&#126;} \eqn{N}(0,\eqn{\gamma}), \eqn{\omega}\out{<sub>i</sub>} \out{&#8869;} u\out{<sub>i</sub>},
u\out{<sub>i</sub>} \out{&#8869;} v\out{<sub>S<sub>i</sub></sub>}, u\out{<sub>i</sub>} \out{&#8869;} v\out{<sub>T<sub>i</sub></sub>}

and 
(v\out{<sub>S<sub>i</sub></sub>},v\out{<sub>T<sub>i</sub></sub>})\out{<sup>T</sup>} \out{&#126;} \eqn{N}(0,\eqn{\Sigma}\out{<sub>v</sub>})

with

{\figure{surromodel2.png}{options: width="100\%"}}

In this model, \eqn{\lambda}\out{<sub>0s</sub>}(t) is the baseline hazard function associated with the 
surrogate endpoint and \eqn{\beta}\out{<sub>S</sub>} the fixed treatment effect (or log-hazard ratio); 
\eqn{\lambda}\out{<sub>0T</sub>}(t) is the baseline hazard function associated with the true endpoint 
and \eqn{\beta}\out{<sub>T</sub>} the fixed treatment effect. \eqn{\omega}\out{<sub>ij</sub>} is a shared individual-level frailty that serve to take into account the 
heterogeneity in the data at the individual level; u\out{<sub>i</sub>} is a shared frailty effect associated 
with the baseline hazard function that serve to take into account the heterogeneity between trials 
of the baseline hazard function, associated with the fact that we have several trials in this 
meta-analytical design. The power parameters \eqn{\zeta} and \eqn{\alpha} distinguish 
both individual and trial-level heterogeneities between the surrogate and the true endpoint. 
v\out{<sub>S<sub>i</sub></sub>} and v\out{<sub>T<sub>i</sub></sub>} are two correlated random effects treatment-by-trial interactions. 
\eqn{Z}\out{<sub>ij1</sub>} represents the treatment arm to which the patient has been randomized.

\bold{Surrogacy evaluation}

We proposed new definitions of Kendall's \eqn{\tau} and coefficient of determination as 
individual-level and trial-level association measurements, to evaluate a candidate 
surrogate endpoint (Sofeu \emph{et al.}, 2018). The formulations are given below.

\bold{Individual-level surrogacy}

To measure the strength of association between \eqn{S}\out{<sub>ij</sub>} and \eqn{T}\out{<sub>ij</sub>} after 
adjusting the marginal distributions for the trial and the treatment effects, as show in 
Sofeu \emph{et al.}(2018), we use the Kendall's \eqn{\tau} define by :

{\figure{surromodel3.png}{options: width="100\%"}}
       
 
 where \eqn{\theta}, \eqn{\zeta}, \eqn{\alpha} and \eqn{\gamma} are estimated using the joint surrogate model
 defined previously. Kendall's \eqn{\tau} is the difference between the probability of 
 concordance and the probability of discordance of two realizations of \eqn{S}\out{<sub>ij</sub>} and \eqn{T}\out{<sub>ij</sub>}. 
 It belongs to the interval [-1,1] and assumes a zero value when \eqn{S}\out{<sub>ij</sub>} and \eqn{T}\out{<sub>ij</sub>} are 
 independent. We estimate Kendall's \eqn{\tau} using Monte-Carlo or Gaussian Hermite
 quadrature integration methods. Its confidence interval is estimated using parametric 
 bootstrap
 
 \bold{Trial-level surrogacy}
 
 The key motivation for validating a surrogate endpoint is to be able to predict the effect 
 of treatment on the true endpoint, based on the observed effect of treatment on the 
 surrogate endpoint. As shown by Buyse \emph{et al.} (2000), the coefficenient of 
 determination obtains from the covariance matrix \eqn{\Sigma}\out{<sub>v</sub>} of the random effects 
 treatment-by-trial interaction can be used to evaluate underlined prediction, and 
 therefore as surrogacy evaluation measurement at trial-level. It is defined by: 
 
 {\figure{surromodel4.png}{options: width="100\%"}}
 
 The SEs of \eqn{R}\out{<sub>trial</sub>}\out{<sup>2</sup>} is calculated using the Delta-method. We also propose 
 \eqn{R}\out{<sub>trial</sub>}\out{<sup>2</sup>} and 95\% CI computed using the parametric bootstrap. The use of delta-method 
 can lead to confidence limits violating the [0,1], as noted by 
 (Burzykowski \emph{et al.}, 2001). However, using other methods would not significantly alter
 the findings of the surrogacy assessment 
 }
 \if{latex}{\bold{Joint Frailty Surrogate model definition} 

Fit the one-step Joint surrogate model for the evaluation of a canditate surrogate endpoint, 
with different integration methods on the random effects, using a semiparametric penalized 
likelihood estimation. This approach extends that of Burzykowski \code{et al.} (2001) by 
including in the same joint frailty model the individual-level and the trial-level random effects.
 
For the \eqn{j^{th}} subject (\code{j=1,\ldots,}\eqn{n_i}) of the \eqn{i^{th}} 
trial \code{i} (\code{i=1,\ldots,}\eqn{G}), the joint surrogate model is defined as follows:

\deqn{\left\{ \begin{array}{ll} \lambda_{S,ij}(t|\omega_{ij},u_i,v_{S_i},{Z_{ij1}}) &= \lambda_{0S}(t) \exp(\omega_{ij}+u_i+
v_{S_i} Z_{ij1} +  \beta_SZ_{ij1}) \\
\lambda_{T,ij}(t|\omega_{ij},u_i,v_{T_i},{Z_{ij1}}) & = \lambda_{0T}(t) \exp({\zeta}\omega_{ij}+
\alpha u_i+v_{T_i} Z_{ij1} + \beta_TZ_{ij1}) \\ \end{array} \right. }

where,

\deqn{ \omega_{ij} \sim N (0,\theta), u_i \sim N (0,\gamma), \omega_{ij} \perp u_i, u_i \perp v_{S_i},
 u_i \perp v_{T_i} }

and 
\eqn{(v_{S_i},v_{T_i})^{T}\sim\mathcal{N}\left({{0}},\Sigma_{v}\right)}, with
\deqn{\Sigma_{v}=\left(
                      \begin{array}{cc} 
                         \sigma^2_{v_S}  &  \sigma_{v_{ST}} \\ 
                         \sigma_{v_{ST}} &  \sigma^2_{v_T}
                      \end{array}
                 \right)}

In this model, \eqn{\lambda_{0S}(t)} is the baseline hazard function associated with the 
surrogate endpoint and \eqn{\beta_S} the fixed treatment effect (or log-hazard ratio); 
\eqn{\lambda_{0T}(t)} is the baseline hazard function associated with the true endpoint 
and \eqn{\beta_T} the fixed treatment effect. \eqn{\omega_{ij}} is a shared individual-level frailty that serve to take into account the 
heterogeneity in the data at the individual level; \eqn{u_i} is a shared frailty effect associated 
with the baseline hazard function that serve to take into account the heterogeneity between trials 
of the baseline hazard function, associated with the fact that we have several trials in this 
meta-analytical design. The power parameters \eqn{\zeta} and \eqn{\alpha} distinguish 
both individual and trial-level heterogeneities between the surrogate and the true endpoint. 
\eqn{v_{S_i}} and \eqn{v_{T_i}} are two correlated random effects treatment-by-trial interactions. 
\eqn{Z_{ij1}} represents the treatment arm to which the patient has been randomized.

\bold{Surrogacy evaluation}

We proposed new definitions of Kendall's \eqn{\tau} and coefficient of determination as 
individual-level and trial-level association measurements, to evaluate a candidate 
surrogate endpoint (Sofeu \emph{et al.}, 2018). The formulations are given below.

\bold{Individual-level surrogacy}

To measure the strength of association between \eqn{S_{ij}} and \eqn{T_{ij}} after 
adjusting the marginal distributions for the trial and the treatment effects, as show in 
Sofeu \emph{et al.}(2018), we use the Kendall's \eqn{\tau} define by :

\deqn{  \begin{array}{ll}
  \tau & = 2\int_{u_{i}}\int_{\omega_{ij}}
    \int_{u_{i'}}\int_{\omega_{i'j'}}\{ \\
    & \frac{\exp(\omega_{ij}+u_{i}+\zeta \omega_{ij}+\alpha u_{i})+\exp(\omega_{i'j'}+u_{i'} + 
    \zeta \omega_{i'j'}+\alpha u_{i'})}{( \exp(\omega_{i'j'}+u_{i'})+ \exp(\omega_{ij}+u_{i})) 
    (\exp(\zeta \omega_{i'j'}+\alpha u_{i'}) + \exp(\zeta \omega_{ij}+\alpha u_{i}))} \\
   & \frac{1}{\sqrt{2\pi \theta}}\exp\left[-\frac{1}{2}\frac{\omega^2_{i'j'}}{\theta}\right]
     \frac{1}{\sqrt{2\pi\gamma}}\exp\left[-\frac{1}{2}\frac{u^2_{i'}}{\gamma}\right]
     d\omega_{i'j'}du_{i'} \\
   & \frac{1}{\sqrt{2\pi\theta}}\exp\left[-\frac{1}{2}\frac{\omega^2_{ij}}{\theta}\right] \frac{1}{\sqrt{2\pi\gamma}}\exp\left[-\frac{1}{2}\frac{u^2_{i}}{\gamma}\right]
     d\omega_{ij}du_{i}\} 
     -1
\\ \end{array} }
       
 
 where \eqn{\theta, \zeta, \alpha} and \eqn{\gamma} are estimated using the joint surrogate model
 defined previously. Kendall's \eqn{\tau} is the difference between the probability of 
 concordance and the probability of discordance of two realizations of \eqn{S_{ij}} and \eqn{T_{ij}}. 
 It belongs to the interval [-1,1] and assumes a zero value when \eqn{S_{ij}} and \eqn{T_{ij}} are 
 independent. We estimate Kendall's \eqn{\tau} using Monte-Carlo or Gaussian Hermite
 quadrature integration methods. Its confidence interval is estimated using parametric 
 bootstrap
 
 \bold{Trial-level surrogacy}
 
 The key motivation for validating a surrogate endpoint is to be able to predict the effect 
 of treatment on the true endpoint, based on the observed effect of treatment on the 
 surrogate endpoint. As shown by Buyse \emph{et al.} (2000), the coefficenient of 
 determination obtains from the covariance matrix \eqn{\Sigma_v} of the random effects 
 treatment-by-trial interaction can be used to evaluate underlined prediction, and 
 therefore as surrogacy evaluation measurement at trial-level. It is defined by: 
 
 \deqn{ R^2_{trial}=\frac{\sigma^2_{v_{ST}}}{\sigma^2_{v_S}\sigma^2_{v_T}}
 }
 
 The SEs of \eqn{R^2_{trial}} is calculated using the Delta-method. We also propose 
 \eqn{R^2_{trial}} and 95\% CI computed using the parametric bootstrap. The use of delta-method 
 can lead to confidence limits violating the [0,1], as noted by 
 (Burzykowski \emph{et al.}, 2001). However, using other methods would not significantly alter
 the findings of the surrogacy assessment 
 }

}
}
\details{
{
The estimated parameter are obtained using the robust Marquardt algorithm
(Marquardt, 1963) which is a combination between a Newton-Raphson algorithm
and a steepest descent algorithm. The iterations are stopped when the
difference between two consecutive log-likelihoods was small
\eqn{(<10^{-3})}, the estimated coefficients were stable (consecutive
values \eqn{(<10^{-3})}, and the gradient small enough \eqn{(<10^{-3})}, by default.
Cubic M-splines of order 4 are used for the hazard function, and I-splines (integrated M-splines) are
used for the cumulative hazard function.

The inverse of the Hessian matrix is the variance estimator and to deal
with the positivity constraint of the variance component and the spline
coefficients, a squared transformation is used and the standard errors are
computed by the \eqn{\Delta}-method (Knight & Xekalaki, 2000). The smooth
parameter can be chosen by maximizing a likelihood cross validation
criterion (Joly and other, 1998). 

We proposed based on the joint surrogate model a new definition 
of the Kendall's \eqn{\tau}. Moreover, distinct numerical integration methods are available to approximate the 
integrals in the marginal log-likelihood.

\bold{Non-convergence case management procedure}

Special attention must be given to initializing model parameters, the choice of the number of 
spline knots, the smoothing parameters and the number of quadrature points to solve convergence 
issues. We first initialized parameters using the user's desired strategy, as specified 
by the option \code{true.init.val}. When numerical or convergence problems are encountered, 
with \code{kappa.use} set to \code{4}, the model is fitted again using a combination of the following strategies: 
vary the number of quadrature point (\code{nb.gh} to \code{nb.gh2} or \code{nb.gh2} to \code{nb.gh})
in case of the use of the Gaussian Hermite quadrature integration (see \code{int.method}); 
divided or multiplied the smoothing parameters (\code{k_1}, \code{k_2}) by 10 or 100 according to 
their preceding values, or used parameter vectors obtained during the last iteration (with a 
modification of the number of quadrature points and smoothing parameters). Using this strategy, 
we usually obtained during simulation the rejection rate less than 3\%. A sensitivity analysis 
was conducted without this strategy, and similar results were obtained on the converged samples, 
with about a 23\% rejection rate. 
}
}
\examples{

# Generation of data to use 
data.sim <- jointSurrSimul(n.obs=600, n.trial = 30,cens.adm=549.24, 
         alpha = 1.5, theta = 3.5, gamma = 2.5, zeta = 1, sigma.s = 0.7, 
         sigma.t = 0.7, rsqrt = 0.8, betas = -1.25, betat = -1.25, 
         full.data = 0, random.generator = 1, seed = 0, nb.reject.data = 0)

\dontrun{
#Surrogacy evaluation based on ganerated data with a combination of Monte Carlo 
#and classical Gaussian Hermite integration.*
# (Computation takes around 5 minutes)

joint.surro.sim.MCGH <- jointSurroPenal(data = data.sim, int.method = 2, 
                   nb.mc = 300, nb.gh = 20)
                   
#Surrogacy evaluation based on ganerated data with a combination of Monte Carlo 
# and Pseudo-adaptive Gaussian Hermite integration.
# (Computation takes around 4 minutes)

joint.surro.sim.MCPGH <- jointSurroPenal(data = data.sim, int.method = 2, 
                   nb.mc = 300, nb.gh = 20, adaptatif = 1)
                   
# Results
summary(joint.surro.sim.MCGH)
summary(joint.surro.sim.MCPGH)

# Data from the advanced ovarian cancer randomized clinical trials.
# Joint surrogate model with \\eqn{\\zeta} fixed to 1, 8 nodes spline 
# and the rescaled survival time. 

data(dataOvarian)
# (Computation takes around 20 minutes)
 
joint.surro.ovar <- jointSurroPenal(data = dataOvarian, n.knots = 8, 
                init.kappa = c(2000,1000), indicator.alpha = 0, nb.mc = 200, 
                scale = 1/365)
# results
summary(joint.surro.ovar)

# data from the adjuvant chemotherapy and resectable gastric cancer 
# meta-analyses :
# Joint surrogate model with initial values for the parameters and the 
# smoothing parameters, and sample for the Monte-Carlo integration
# generated by the subroutine \\code{uniran}.
# (Computation takes around 14 minutes)

data(gastadj)
joint.surro.gast <- jointSurroPenal(data = gastadj, nb.mc = 100, nb.gh = 20, 
                indicator.zeta = 0, indicator.alpha = 0, n.knots = 10, 
                random.generator = 2, init.kappa = c(367700100,10025184521))

# results
summary(joint.surro.gast)

}

}
\references{
Burzykowski, T., Molenberghs, G., Buyse, M., Geys, H., and Renard, D. (2001). Validation
of surrogate end points in multiple randomized clinical trials with failure time end points. 
Journal of the Royal Statistical Society: Series C (Applied Statistics) 50, 405-422.

Buyse, M., Molenberghs, G., Burzykowski, T., Renard, D., and Geys, H. (2000). The validation
of surrogate endpoints in meta-analyses of randomized experiments. Biostatistics 1, 49-67

Sofeu C.L., Emura T. and Rondeau V. (2018). One-step validation method for surrogate 
endpoints in multiple randomized cancer clinical trials with failure-time endpoints. 
\code{Under review}
}
\seealso{
\code{\link{jointSurrSimul}}, \code{\link{summary.jointSurroPenal}}, \code{\link{jointSurroPenalSimul}}
}
\author{
Casimir Ledoux Sofeu \email{casimir.sofeu@u-bordeaux.fr}, \email{scl.ledoux@gmail.com} and 
Virginie Rondeau \email{virginie.rondeau@inserm.fr}
}
